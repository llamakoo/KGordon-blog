---
layout: post
title: InGAN
date: 2019-01-11
comments: true
categories: [paper-review]
tags: [neural_rendering]
---

> Generative Adversarial Networks (GANs) typically learn a distribution of images in a large image dataset, and are then able to generate new images from this distribution. However, **each natural image has its own internal statistics, captured by its unique distribution of patches.** In this paper we propose an “Internal GAN” (InGAN) – an image-specific GAN – **which trains on a single input image and learns its internal distribution of patches.** It is then able to synthesize a plethora of new natural images ofsignificantly different sizes, shapes and aspect-ratios all with the same internal patch-distribution (same “DNA”) as the input image. In particular, despite large changes in global size/shape of the image, all elements inside the im- age maintain their local size/shape. InGAN is **fully unsupervised, requiring no additional data other than the input image itself.** Once trained on the input image, it can remap the input to any size or shape in a single feedforward pass, while preserving the same internal patch distribution. InGAN provides a unified framework for a variety of tasks, bridging the gap between textures and natural images. - Abstract of the paper

- Table of Contents
{:toc .large-only}

## Summary
---
- 이미지는 고유한 internal statistics가 존재하며, 반복되어 나타나는 패치들과 같은 경우를 예로 들 수 있다.
- 본 논문에서는 단일 이미지의 고유한 patch 분포를 학습하여, 새로운 크기, 형태의 이미지로 변형하는 기법에 대한 연구결과를 소개한다.

## Problem Settings
---
<figure>
  <img src="https://drive.google.com/uc?id=1Q9bvaAUswU9VmKDLFKgSaSDzl25R6e4g" style="width:100%">
  <figcaption>단순히 이미지 크기를 변형하는 것이 아닌, 패턴 texture의 크기를 유지하며 이미지에 맞게 생성한다.</figcaption>
</figure>

- Fig1과 같은 기능을 위해서 다양한 스케일로 입력 이미지의 패치의 분포와 target 이미지의 패치의 분포가 매칭 되어야 하며
  **"Distribution-Matching"**이라는 용어로 설명한다.
- "Distribution-Matching"은 기존에 연구되었던 Bidirectional-Similarity와 유사하지만 차이점이 있으며 아래와 같다.
    - 모든 입력 패치가 출력 이미지에 존재하여야 할뿐만 아니라, 패치의 빈도도 동일하게 유지
    - 개별 패치를 매칭하는 것이 아닌, 분포를 매칭하기 때문에 GAN 학습 방법을 이용할 수 있다.
    - 원하는 출력 형태에 구애받지 않고 학습된 동일한 네트워크를 기반으로 다양한 크기/모양의 이미지를 생성할 수 있다. <br>(새로운 학습이 필요하지 않음)

- GAN은 주로 대용량 이미지 데이터의 분포를 학습하고, 하나의 분포에서 샘플링 된 데이터를 변환된 데이터에 매핑한다.

## EdgeConnect
---

<figure>
  <img src="https://drive.google.com/uc?id=1Tc042FFo1dW8I-KgPnqsRW6PX6Qr7kZ-" style="width:100%">
  <figcaption>EdgeConnect 네트워크는 two-stage로 inpainting을 수행한다. </figcaption>
</figure>

- 2개의 generator로 구성된다. (학습시 각각의 discriminator가 붙는다)
- 첫번째, edge generator는 빈 영역의 edge를 추정하여 완성된 edge map을 생성한다. 두번째, image completion network는
  생성된 edge map과 hole이 존재하는 rgb 이미지를 입력받아 최종 inpainting된 영상을 생성한다.
- 각 generator는 동일한 구조를 가지며, discriminator로는 70x70 PatchGAN을 사용한다. 

### Edge Generator

$$
\begin{aligned} %!!15
\min _{G_{1}} \max _{D_{1}} \mathcal{L}_{G_{1}}=\min _{G_{1}}\left(\lambda_{a d v, 1} \max _{D_{1}}\left(\mathcal{L}_{a d v, 1}\right)+\lambda_{F M} \mathcal{L}_{F M}\right)
\end{aligned}
$$

An objective function of edge generator
{:.figcaption}

- edge generator에는 3종류의 데이터가 입력된다. $$\mathbf{C}_{\text {pred }}=G_{1}\left(\tilde{\mathbf{I}}_{\text {gray }}, \tilde{\mathbf{C}}_{g t}, \mathbf{M}\right)$$
- edge generator를 학습할 때, objective function은 adversarial loss와 feature-matching loss간의 합으로 구성된다.
- feature-matching loss은 생성된 이미지가 실제 이미지와 유사하도록 하는 학습과정을 더 안정적이게 해준다.
- 최근 대다수의 이미지 생성 논문들은 feature-matching loss와 perceptual loss를 결합하여 사용하는데,
  학습된 VGG 네트워크를 사용하는 perceptual loss는 edge 정보를 생성하는데 적합하지 않으므로 본 edge generator를 학습할때는 적합하지 않아서 배제하였다고 한다.
- generator와 discriminator에 SN(Spectral normalization)을 적용하였다. 이는 네트워크의 gradient값과 파라미터가
  갑자기 변동하는 것을 경감해주는데 이점이있다.

### Image Completion Network

$$
\begin{aligned} %!!15
\mathcal{L}_{G_{2}}=\lambda_{\ell_{1}} \mathcal{L}_{\ell_{1}}+\lambda_{a d v, 2} \mathcal{L}_{a d v, 2}+\lambda_{p} \mathcal{L}_{\text {perc }}+\lambda_{s} \mathcal{L}_{\text {style }}
\end{aligned}
$$

An objective function of image completion network
{:.figcaption}
- image completion network에는 두가지 데이터가 입력된다. edge generator가 추정한 edge map과 hole이 있는 rgb 영상이다.
- objective function은 L1 loss, Adversarial loss, perceptual loss, style loss가 사용된다.
  이는 최근 이미지 생성 논문들에서 많이 쓰이는 조합이다.
- edge generator와는 다르게 SN을 사용하지 않았는데, 저자는 SN을 사용할 경우 학습시간이 방대하게 증가하기 때문이다고 한다.

## Experiments
---
- train label로 사용할 edge map은 Canny edge detector를 사용하여 만들었다.
- train label로 사용하는 mask는 2가지가 있는데, 사각형 모양의 mask와 irregular한 모양의 mask를 사용하였다.
- 학습 방법으로는 2가지 generator를 각각 따로 학습하며, 학습이 완료되고 다시 2개의 generator를 jointly하게 학습한다.
  jointly하게 학습할 때는 image completion network의 discriminator만 사용한다.

<figure>
  <img src="https://drive.google.com/uc?id=1fBEgpx-_AykJ8KB0l2Hda6gWxk5FwacE" style="width:100%">
  <figcaption>다른 inpainting 기법들과의 비교 결과. 기타 방법들 대비 좋은 성능을 보인다.</figcaption>
</figure>

- 저자들은 edge가 주어지면, image completion network가 이미지의 구조정보는 고려하지 않고 칼라 분포만 학습하면 되기 때문에 효과적인 결과를 보인다고 추측한다.

<figure>
  <img src="https://drive.google.com/uc?id=1N2QfDNkND2gqgrbnJKmMtzTpjlcA99fv" style="width:100%">
</figure>

- Figure4를 보면, 왼쪽부터 원본 이미지, 입력 이미지, 생성된 edge map, inpainted 이미지의 결과를 보여준다.
- 또한 정량적 평가로 SSIM, PSNR, FID 수치를 비교하였으며 기타 알고리즘 대비 높은 수치를 보여준다.
- 저자들은 또한 여러가지 ablation 평가를 진행하였는데 간단히 종합해보면,
    - edge 정보가 주어질 때 inpainting도 더욱 효과적인 결과를 보여준다.
    - edge map에 edge 성분이 너무 과하여도 너무 적어도 좋지 않으며, 적당한 edge 성분일 때 좋은 결과를 보여준다.
    - Canny edge detector가 아닌 기타 edge detector를 사용하였지만 결과에서 큰 차이를 보이지 않았다.
    - edge map을 사용자가 조절하여 변형된 구조의 이미지를 생성할 수도 있다. 또한 본 알고리즘으로 이미지의 원하지 않는 부분을 지울수 있다.


## Paper Info
---
> Title : InGAN, Capturing and Remapping the "DNA" of a Natural Image

> Paper link : [Shocher_InGAN_Capturing_and_Retargeting_the_DNA_of_a_Natural_Image_ICCV_2019_paper.pdf](https://openaccess.thecvf.com/content_ICCV_2019/papers/Shocher_InGAN_Capturing_and_Retargeting_the_DNA_of_a_Natural_Image_ICCV_2019_paper.pdf)

> Project page : [http://www.wisdom.weizmann.ac.il/~vision/ingan/](http://www.wisdom.weizmann.ac.il/~vision/ingan/)

> Publised year : 1 Jan 2019

> Authors : Assaf Shocher, Shai Bagon, Phillip Isola, Michal Irani

---


<br>